{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Netflix job postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like some other companies, Netflix posts its job offers at a platform called Lever. **Netflix job postings** can be found at `jobs.lever.co/netflix`. I call this page the **main page**. It will display, the day you visit it, about 500 postings. The postings can be filtered by city, team and work type. Most of the postings on display are for teams in from the Streaming division.\n",
    "\n",
    "The main page contains, for each available position, basic information about the job, such as the job title, the location and the team, and a link to a page specific for that position, such as `jobs.lever.co/netflix/2d11d912-bfb3-4d9d-bfa1-0ce036214284`. I call that specific page the **individual page**. The individual page presents a description of the company and the role of the new employee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing the source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HTTP** is a protocol for communication between clients and servers. For instance, a client (such as your browser) sends a **HTTP request** to the server. Then the server returns the response to the client. The response contains status information about the request and, when the request is accepted, the requested content. \n",
    "\n",
    "**GET** is one of the most common HTTP methods. It is used to request data from a specified resource. In the Python package `requests`, the function `get` is an implementation of the HTTP method GET. `requests` comes with the Anaconda distribution, so we can import it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `request` function `get` returns an object of a special type (type `requests.models.Response`). The attribute `text` of this object is a string which, for an ordinary web page, is the HTML source code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://jobs.lever.co/netflix').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `page` is a string containing the source code of the Netflix Lever main page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse HTML code and to learn the tree structure it conveys, I use the package `lxml` (not the only option). More specifically, the function `fromstring` from the subpackge `html`. We import this subpackage with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.fromstring(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fromstring` returns a special `lxml` object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lxml.html.HtmlElement"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the ID's for the job postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to extract from `tree` the three pieces of information I am interested in, by means of adequate **XPath expressions**. How can find an adequate XPath expression? There are many ways, and every web scraper has his/her own cookbook. The simplest approach is based on the *Inspect* tool of the browser. Right-click on the *APPLY* button of a job post, opening a contextual menu, and select *Inspect*. This will open a window showing a view of the source code in which the node containing a link to the page of that job post is highlighted. \n",
    "\n",
    "Let me start with the ID's of the job postings. The nodes containing the ID his node are `div` nodes which have the ID as the value of the attribute `data-qa-posting-id`. So I use the XPath expression `'//div/@data-qa-posting-id'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4dfd6b7b-e020-44ae-a9f5-64b631b20e9c',\n",
       " 'a1291f11-99e7-4213-87c0-fcbac8e4c6a7',\n",
       " 'f5296ea6-b3bd-4cf1-9167-268e70218838',\n",
       " 'e8999fd7-e3ac-4af3-8667-0bd002123528',\n",
       " '44b91dcb-0735-4b94-a171-81c43133e5c1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = tree.xpath('//div/@data-qa-posting-id')\n",
    "id[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get a list with the ID's of 523 job postings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The links to the individual pages can be directly obtained from the ID's (they can also be scraped with an adequate XPath expression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://jobs.lever.co/netflix/4dfd6b7b-e020-44ae-a9f5-64b631b20e9c',\n",
       " 'https://jobs.lever.co/netflix/a1291f11-99e7-4213-87c0-fcbac8e4c6a7',\n",
       " 'https://jobs.lever.co/netflix/f5296ea6-b3bd-4cf1-9167-268e70218838',\n",
       " 'https://jobs.lever.co/netflix/e8999fd7-e3ac-4af3-8667-0bd002123528',\n",
       " 'https://jobs.lever.co/netflix/44b91dcb-0735-4b94-a171-81c43133e5c1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = ['https://jobs.lever.co/netflix/' + i for i in id]\n",
    "link[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow a similar approach to extract the job titles. Using *Inspect* with a job title, we find it as the value of a `h5` node, with a `data-qa` attribute whose value is `\"posting-name\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead Technical Director - Wendell & Wild',\n",
       " 'Render Wrangler/Jr. Technical Director - Wendell & Wild',\n",
       " '2D Background Layout Artist - Blue Eye Samurai',\n",
       " 'Art Director - Blue Eye Samurai',\n",
       " 'Background Layout Supervisor - Blue Eye Samurai']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = tree.xpath('//h5[@data-qa=\"posting-name\"]/text()')\n",
    "job[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the job location, which is found as the value of a `span` node with a `class` attribute whose value is `\"sort-by-location posting-category small-category-label\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oregon',\n",
       " 'Oregon',\n",
       " 'Los Angeles, California',\n",
       " 'Los Angeles, California',\n",
       " 'Los Angeles, California']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = tree.xpath('//span[@class=\"sort-by-location posting-category small-category-label\"]/text()')\n",
    "location[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team is the least piece of information that we scrape from this page. It is found as the value of a `span` node which has a `class` attribute whose value is `\"sort-by-team posting-category small-category-label\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation – Animation',\n",
       " 'Animation – Animation',\n",
       " 'Animation – Art',\n",
       " 'Animation – Art',\n",
       " 'Animation – Art']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = tree.xpath('//span[@class=\"sort-by-team posting-category small-category-label\"]/text()')\n",
    "team[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team comes in two parts: (a) a division, such *Animation* or *Gaming*, and (b) a department, such as *Art* or *Production Management*. It might be interesting to split it in these two parts, which are separated by a symbol which looks like a hyphen but it is a bit longer. It is the **en dash** (see `jkorpela.fi/dashes.html` if you are curious about this). You can copypaste it in a Jupyter interface, or use the Unicode representation \\u2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Animation', 'Animation'],\n",
       " ['Animation', 'Animation'],\n",
       " ['Animation', 'Art'],\n",
       " ['Animation', 'Art'],\n",
       " ['Animation', 'Art']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = [t.split(' – ') for t in team]\n",
    "team[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the split has been performed, I name the two parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation', 'Animation', 'Animation', 'Animation', 'Animation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "division = [t[0] for t in team]\n",
    "division[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation', 'Animation', 'Art', 'Art', 'Art']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept = [t[1] for t in team]\n",
    "dept[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **JSON** (JavaScript Object Notation) format is very practical for storing certain types of information, such as Twitter or news data, for which the tabular format is not adequate. A JSON document is a collection of **pairs key/value**, organized in a special way, which accounts for a hierarchy of information. For instance, the following example stores family information:\n",
    "\n",
    "    [{'Name': 'John', 'Age': 27},\n",
    "\n",
    "     {'Name': 'Peter', 'Age': 32, 'Children': 'Louis'},\n",
    "\n",
    "     {'Name': 'Maria', 'Age': 29, 'Children': ['Edward', 'Christine']}]\n",
    " \n",
    "In this example, you can see how to include information about the children in a flexible way, allowing for zero, one or more children. To use a tabular format for these data, you would have to create a collection of columns \"Child1\", \"Child2\", etc, with many missing values. The flexible structure of JSON allows you to cope with different family sizes in a simple way. \n",
    "\n",
    "To the Pythonista, the JSON document looks like a nested structure of lists and dictionaries. This makes straightforward importing and exporting JSON data in Python. The package `json`, which is part of the Python Standard Library, allows this functionality.\n",
    "\n",
    "Now, a more complex example. The following JSON document has been extracted from the Lever webpage of one of the Netflix job posts:\n",
    "\n",
    "    {\"@context\" : \"http://schema.org\",\n",
    "     \"@type\" : \"JobPosting\",\n",
    "     \"title\" : \"Senior Systems Development Engineer\",\n",
    "     \"hiringOrganization\" : \n",
    "         {\"@type\" : \"Organization\",\n",
    "          \"name\": \"Netflix\",\n",
    "          \"logo\": \"https://lever-client-logos.s3.amazonaws.com/84963f7c-5208-4789-813f-59b515174479-1442905953849.png\"},\n",
    "     \"jobLocation\":\n",
    "         {\"@type\" : \"Place\",\n",
    "              \"address\" :\n",
    "              {\"@type\" : \"PostalAddress\",\n",
    "               \"addressLocality\" : \"Los Angeles, California\",\n",
    "               \"addressRegion\" : null,\n",
    "               \"addressCountry\" : null,\n",
    "               \"postalCode\" : null}},\n",
    "     \"employmentType\" : null,\n",
    "     \"datePosted\" : \"2019-10-05\",\n",
    "     \"description\" : \"The Creative Compute and Storage team designs, develops and delivers technology infrastructure globally for the evolving needs of our creatives. As we continue to expand our content creation globally, we are looking for the best and brightest engineering talent to be part of our growth. \\n\\nOur team is looking for a Senior Systems Development Engineer to be part of the development and build-out of our purposefully developed infrastructure platforms. You will work with internal engineering teams, technical creatives, production teams and external vendors around the world to deliver amazing technology experiences for our creative users. We are looking for an experienced engineer that brings a broad set of technical skills and achievements, a development and automation focused mindset to solving problems and unique career and life experiences to join our teams as we continue to evolve entertainment around the world.\\n\\nBe sure to review our culture page and long-term view to learn more about the unique Netflix culture and the opportunity to be part of our team.\\n\\n\"}\n",
    "\n",
    "This is one record. Sometimes these units are managed separately, as in this case, which is related to a single job post, but they can come in a list, enclosed in square brackets, as in our former example. Please, note that the indentation has been added after copying the JSON document from the source page, to help you to see the structure. Webpage maintainers are rarely so polite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The package json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import `json` as usual in small packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package `json` provides two basic functions, `loads` and `dumps`, which convert a JSON string to either a list or a dictionary, and conversely. This is needed, since in Python every object has a type. To illustrate this point, suppose that we enter our first JSON example to a Python shell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = [{'Name': 'John', 'Age': 27},\n",
    "     {'Name': 'Peter', 'Age': 32, 'Children': 'Louis'},\n",
    "     {'Name': 'Maria', 'Age': 29, 'Children': ['Edward', 'Christine']}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this to a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"Name\": \"John\", \"Age\": 27}, {\"Name\": \"Peter\", \"Age\": 32, \"Children\": \"Louis\"}, {\"Name\": \"Maria\", \"Age\": 29, \"Children\": [\"Edward\", \"Christine\"]}]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_doc = json.dumps(json_list)\n",
    "json_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse this string, recovering the list of dictionaries:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'John', 'Age': 27},\n",
       " {'Name': 'Peter', 'Age': 32, 'Children': 'Louis'},\n",
       " {'Name': 'Maria', 'Age': 29, 'Children': ['Edward', 'Christine']}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. On the fly, `json_loads` performs, when needed, some conversions from Java to Python, such as `null` to `None`, ot `true` to `True`. Also, the quotes are double in `json_doc`, because that is the rule of the JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some webpages include a JSON document in a `script` node. In general, `script` nodes are used in HTML code to embed executable code or data. Although most of those nodes embed or refer to JavaScript code, they can also be used to store metadata in JSON format. In this case, they have the attribute `type=\"application/ld+json\"`. Sometimes, these JSON documents contain information which can also be found in other parts of the web page. They are used to mark up web contents so that they can be understood by major search engines as Google and Bing. The data stored in `script` nodes is not displayed by the browser.\n",
    "\n",
    "Let us see how this works for the individual pages of the Netflix jobs. The link for the first job is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://jobs.lever.co/netflix/4dfd6b7b-e020-44ae-a9f5-64b631b20e9c'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a page containing detail for a post related to a Senior Systems Development Engineer position. By applying `request.get`, I capture the source as a string. Then I parse that string with `html.fromstring`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(link[0]).content\n",
    "tree = html.fromstring(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potential JSON documents contained in `script` nodes as described above are easy to get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_doc = tree.xpath('//script[@type=\"application/ld+json\"]/text()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xpath` rerturns a list, which can have any length, depending on the number of elements of this type included in the source code. In this case, I am lucky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the single element of this list with `json.loads`. I call the outcome `json_dict`, becuase it is a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict = json.loads(json_doc[0])\n",
    "type(json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an insight on the contents, I list the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@context', '@type', 'title', 'hiringOrganization', 'jobLocation', 'employmentType', 'datePosted', 'description'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The employment type, the date the job was posted and the description are potentially interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contractor'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict['employmentType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-17'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict['datePosted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With over 204 million subscribers enjoying great content in over 190 countries, it’s an exciting time to work at Netflix.\\xa0\\n\\nBy serving as a platform for original storytelling, we’re fueled by the broad appeal of being able to instantly enjoy unlimited movies and TV shows and seek to create joy for our members around the world. This guiding principle has informed our commitment to animation, a universal language, and the establishment of Netflix Animation Studios where creative visionaries can perform their best work.\\xa0\\n\\nThis is the new wave of animation — and you can help shape it. Our goal is to tell stories that no one has seen but that everyone will remember.\\n\\n\\n\\nLooking for someone to start ASAP!\\nEstimated project end date: 12/17/2021\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to scrape information from an individual page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to capture this information for all postings. But there are 523 postings, so we need a procedure to do massively what we have done with one postings. People typically use loops for this kind of massive repetitions. Creating a function which scrapes the information from an individual page simplifies the code.\n",
    "\n",
    "In the definition of the **scraping function** I just collect the operations that I have performed above, using the link as the argument of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(l):\n",
    "    page = requests.get(l).content\n",
    "    tree = html.fromstring(page)\n",
    "    json_doc = tree.xpath('//script[@type=\"application/ld+json\"]/text()')\n",
    "    json_dict = json.loads(json_doc[0])\n",
    "    return [json_dict['employmentType'], json_dict['datePosted'], json_dict['description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check that this works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contractor',\n",
       " '2021-06-17',\n",
       " 'With over 204 million subscribers enjoying great content in over 190 countries, it’s an exciting time to work at Netflix.\\xa0\\n\\nBy serving as a platform for original storytelling, we’re fueled by the broad appeal of being able to instantly enjoy unlimited movies and TV shows and seek to create joy for our members around the world. This guiding principle has informed our commitment to animation, a universal language, and the establishment of Netflix Animation Studios where creative visionaries can perform their best work.\\xa0\\n\\nThis is the new wave of animation — and you can help shape it. Our goal is to tell stories that no one has seen but that everyone will remember.\\n\\n\\n\\nLooking for someone to start ASAP!\\nEstimated project end date: 12/17/2021\\n']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping over the individual pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loop needs a place to start. We set this as an empty list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "employmentType, datePosted, description = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we create a loop which adds the outcome of our scraping for every link, one-by-one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in link:\n",
    "    data = f(l)\n",
    "    employmentType = employmentType + [data[0]]\n",
    "    datePosted = datePosted + [data[1]]\n",
    "    description = description + [data[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. It may be that the loop stops before attaining the end of the links' list. This may be due to various reasons: the connection fails, the server decides that you are robot, etc. In that case, you can restart the loop at the point it stopped, which you can learn from the length of the lists that you have already obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the information collected in a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now pack as a data frame the information collected, so that it can be easily exported to text file or a database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'job': job, 'location': location, 'division': division, 'dept': dept,\n",
    "  'employmentType': employmentType, 'datePosted': datePosted, 'description': description}, index=id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 523 entries, 4dfd6b7b-e020-44ae-a9f5-64b631b20e9c to 836292b3-4b02-4f35-97f7-0b9e4aeda4e7\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   job             523 non-null    object\n",
      " 1   location        523 non-null    object\n",
      " 2   division        523 non-null    object\n",
      " 3   dept            523 non-null    object\n",
      " 4   employmentType  520 non-null    object\n",
      " 5   datePosted      523 non-null    object\n",
      " 6   description     523 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 32.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>location</th>\n",
       "      <th>division</th>\n",
       "      <th>dept</th>\n",
       "      <th>employmentType</th>\n",
       "      <th>datePosted</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4dfd6b7b-e020-44ae-a9f5-64b631b20e9c</th>\n",
       "      <td>Lead Technical Director - Wendell &amp; Wild</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>With over 204 million subscribers enjoying gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1291f11-99e7-4213-87c0-fcbac8e4c6a7</th>\n",
       "      <td>Render Wrangler/Jr. Technical Director - Wende...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>With over 204 million subscribers enjoying gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5296ea6-b3bd-4cf1-9167-268e70218838</th>\n",
       "      <td>2D Background Layout Artist - Blue Eye Samurai</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Art</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>With over 204 million subscribers enjoying gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e8999fd7-e3ac-4af3-8667-0bd002123528</th>\n",
       "      <td>Art Director - Blue Eye Samurai</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Art</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>With over 204 million subscribers enjoying gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44b91dcb-0735-4b94-a171-81c43133e5c1</th>\n",
       "      <td>Background Layout Supervisor - Blue Eye Samurai</td>\n",
       "      <td>Los Angeles, California</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Art</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>With over 204 million subscribers enjoying gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    job  \\\n",
       "4dfd6b7b-e020-44ae-a9f5-64b631b20e9c           Lead Technical Director - Wendell & Wild   \n",
       "a1291f11-99e7-4213-87c0-fcbac8e4c6a7  Render Wrangler/Jr. Technical Director - Wende...   \n",
       "f5296ea6-b3bd-4cf1-9167-268e70218838     2D Background Layout Artist - Blue Eye Samurai   \n",
       "e8999fd7-e3ac-4af3-8667-0bd002123528                    Art Director - Blue Eye Samurai   \n",
       "44b91dcb-0735-4b94-a171-81c43133e5c1    Background Layout Supervisor - Blue Eye Samurai   \n",
       "\n",
       "                                                     location   division  \\\n",
       "4dfd6b7b-e020-44ae-a9f5-64b631b20e9c                   Oregon  Animation   \n",
       "a1291f11-99e7-4213-87c0-fcbac8e4c6a7                   Oregon  Animation   \n",
       "f5296ea6-b3bd-4cf1-9167-268e70218838  Los Angeles, California  Animation   \n",
       "e8999fd7-e3ac-4af3-8667-0bd002123528  Los Angeles, California  Animation   \n",
       "44b91dcb-0735-4b94-a171-81c43133e5c1  Los Angeles, California  Animation   \n",
       "\n",
       "                                           dept employmentType  datePosted  \\\n",
       "4dfd6b7b-e020-44ae-a9f5-64b631b20e9c  Animation     Contractor  2021-06-17   \n",
       "a1291f11-99e7-4213-87c0-fcbac8e4c6a7  Animation     Contractor  2021-06-17   \n",
       "f5296ea6-b3bd-4cf1-9167-268e70218838        Art     Contractor  2021-05-04   \n",
       "e8999fd7-e3ac-4af3-8667-0bd002123528        Art     Contractor  2020-04-26   \n",
       "44b91dcb-0735-4b94-a171-81c43133e5c1        Art     Contractor  2021-06-16   \n",
       "\n",
       "                                                                            description  \n",
       "4dfd6b7b-e020-44ae-a9f5-64b631b20e9c  With over 204 million subscribers enjoying gre...  \n",
       "a1291f11-99e7-4213-87c0-fcbac8e4c6a7  With over 204 million subscribers enjoying gre...  \n",
       "f5296ea6-b3bd-4cf1-9167-268e70218838  With over 204 million subscribers enjoying gre...  \n",
       "e8999fd7-e3ac-4af3-8667-0bd002123528  With over 204 million subscribers enjoying gre...  \n",
       "44b91dcb-0735-4b94-a171-81c43133e5c1  With over 204 million subscribers enjoying gre...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "**Kraken** is a US-based cryptocurrency exchange and bank, founded in 2011. They provide cryptocurrency-to-fiat-money trading, and provides price information to Bloomberg Terminal. At `jobs.lever.co/kraken`, you will find a job posting site, organized in the same way as Netflix's site. Capture the information about the Kraken job posts that you find interesting and summarize it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
