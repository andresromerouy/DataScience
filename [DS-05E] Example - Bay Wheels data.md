# [DS-05E] Example - Bay Wheels data

## Introduction

**Bike sharing systems** are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout an urban area. Using these systems, people are able to rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world, involving more than 500 thousand bicycles. Nowadays, there is a great interest in these systems due to their important role in traffic, environmental and health issues.

Apart from interesting real world applications of bike sharing systems, the characteristics of the data generated by these systems makes them attractive for researchers. Opposed to other transport services such as bus or subway, the duration of travel, departure location, arrival location and time elapsed is explicitly recorded. This feature turns bike sharing system into a virtual sensor network, which can be used for studying mobility within the area. Hence, it is expected that most of important events in the area could be detected via monitoring these data.

The **Bay Wheels Bike Share Program** brings affordable, accessible point-to-point bike sharing to Bay Area cities, serving Berkeley, Emeryville, Oakland, San Jose and San Francisco. Bay Wheels is a partnership between MTC, the five local governments, and Motivate (a subsidiary of Lyft). This example uses two years of data from the Bay Wheels program. The program has undergone a bit of change. It started as the Bay Area Bike Share in August 2013. On June 28, 2017, the system was officially re-launched as Ford GoBike in a partnership with Ford Motor Company. After Motivate's acquisition by Lyft, the system was renamed to Bay Wheels on June 11, 2019. 

In 2018, Ford GoBike added **electric bicycles** and **dockless bike share**. Nowadays, electric bicycles account for two thirds of the rides. Classic bikes are docked, so they are picked at one station and left at another station (or at the same one). E-bikes can use the **docking stations** or can be locked to a **city bike rack**.

### The data set

The data for the example come in two tables. The table `bay_stations` contains data on 507 docking stations. The columns are:

* `station_id`, a unique identifier of the station. The first two characters indicate the location, with values 'BK' (Berkeley), 'SF' (San Francisco), 'SJ' (San Jose) and 'OK' (Oakland).

* `station_name`, the name of the station, referred to its location. 

* `station_latitude`, the latitude of the station, with three decimals.

* `station_longitude`, the longitude of the station, with three decimals.

The table `bay_rides` (in three zipped CSV files) contains information on all rides starting in the years 2021 and 2022, a total of 4,602,456 rides. The columns are:

* `user_type`, either 'casual' or 'member'.

* `bike_type`, either `classic` or `electric`.

* `start_time`, when the bike was picked, as 'yyyy-mm-dd hh:mm:ss'. 

* `start_station_id`, the identifier of the docking station where the ride started, missing when no station was involved.

* `end_time`, when the bike was returned, as 'yyyy-mm-dd hh:mm:ss'. 

* `end_station_id`, the identifier of the docking station where the ride ended, missing when no station was involved.

## Questions

Q1. Add a column `hour` to the table `rides`, containing the hour of the start time, in `datetime64` format. Example: the hour for `2021-01-01 01:20:23` will be `2021-01-01 01:00:00`.

Q2. Group by `hour` and aggregate so you get a a new table with two columns, `casual` and `member` containing, for every hour, the total number of rides of the types of users. 

Q3. After aggregating the data in the preceding question, can see you see a time trend in the number of rides? To visualize the trend, would it be better to aggregate more, *e.g*. to use daily data? Do you see a similar trend for the two types of users?

Q4. Can you describe in an easy way the pattern for intraday variation (across hours) of the number of rides? Is this pattern different for the two user types?

Q5. Same questions for intraweek variation (across weekdays).

Q6. What about monthly seasonality?

## Importing the data

```
In [1]: import pandas as pd
```

```
In [2]: path = 'https://raw.githubusercontent.com/cinnData/DataSci/main/Data/'
```

```
In [3]: rides1 = pd.read_csv(path + 'bay_rides-1.csv.zip')
   ...: rides2 = pd.read_csv(path + 'bay_rides-2.csv.zip')
   ...: rides3 = pd.read_csv(path + 'bay_rides-3.csv.zip')
```

```
In [4]: rides = pd.concat([rides1, rides2, rides3])
```

## Exploring the data

```
In [5]: rides.info()
<class 'pandas.core.frame.DataFrame'>
Index: 4602456 entries, 0 to 1602455
Data columns (total 6 columns):
 #   Column            Dtype 
---  ------            ----- 
 0   user_type         object
 1   bike_type         object
 2   start_time        object
 3   start_station_id  object
 4   end_time          object
 5   end_station_id    object
dtypes: object(6)
memory usage: 245.8+ MB
```
```
In [6]: rides.head()
Out[6]: 
  user_type bike_type           start_time start_station_id   
0    casual  electric  2021-01-01 00:01:01              NaN  \
1    member   classic  2021-01-01 00:01:11           SF-I24   
2    member  electric  2021-01-01 00:01:44              NaN   
3    casual  electric  2021-01-01 00:03:44         SF-G30-1   
4    casual  electric  2021-01-01 00:05:33              NaN   

              end_time end_station_id  
0  2021-01-01 00:31:31            NaN  
1  2021-01-01 00:21:46         SF-L29  
2  2021-01-01 01:01:05            NaN  
3  2021-01-01 00:44:51            NaN  
4  2021-01-01 00:22:02            NaN  
```

## Q1. Add a column with the hour

```
In [7]: rides['hour'] = rides['start_time'].str.replace(':[0-9]{2}:[0-9]{2}', ':00:00', regex=True)
   ...: rides.head()
Out[7]: 
  user_type bike_type           start_time start_station_id   
0    casual  electric  2021-01-01 00:01:01              NaN  \
1    member   classic  2021-01-01 00:01:11           SF-I24   
2    member  electric  2021-01-01 00:01:44              NaN   
3    casual  electric  2021-01-01 00:03:44         SF-G30-1   
4    casual  electric  2021-01-01 00:05:33              NaN   

              end_time end_station_id                 hour  
0  2021-01-01 00:31:31            NaN  2021-01-01 00:00:00  
1  2021-01-01 00:21:46         SF-L29  2021-01-01 00:00:00  
2  2021-01-01 01:01:05            NaN  2021-01-01 00:00:00  
3  2021-01-01 00:44:51            NaN  2021-01-01 00:00:00  
4  2021-01-01 00:22:02            NaN  2021-01-01 00:00:00  
```

```
In [8]: rides['hour'] = rides['hour'].astype('datetime64[ns]')
   ...: rides['hour']
Out[8]: 
0         2021-01-01 00:00:00
1         2021-01-01 00:00:00
2         2021-01-01 00:00:00
3         2021-01-01 00:00:00
4         2021-01-01 00:00:00
                  ...        
1602451   2022-12-31 23:00:00
1602452   2022-12-31 23:00:00
1602453   2022-12-31 23:00:00
1602454   2022-12-31 23:00:00
1602455   2022-12-31 23:00:00
Name: hour, Length: 4602456, dtype: datetime64[ns]

```

## Q2. Aggregate to hourly data

```
In [9]: rides['casual'] = rides['user_type'] == 'casual'
   ...: rides['member'] = rides['user_type'] == 'member'
```

```
In [10]: rides = rides.drop(columns=['bike_type', 'user_type', 'start_time', 'start_station_id', 'end_time', 'end_station_id'])
```

```
In [11]: df = rides.groupby(by='hour').sum()
    ...: df.head()
Out[11]: 
                     casual  member
hour                               
2021-01-01 00:00:00      39      21
2021-01-01 01:00:00      48      27
2021-01-01 02:00:00      41       9
2021-01-01 03:00:00      18       7
2021-01-01 04:00:00      12       4
```

```
In [12]: df.index
Out[12]: 
DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 01:00:00',
               '2021-01-01 02:00:00', '2021-01-01 03:00:00',
               '2021-01-01 04:00:00', '2021-01-01 05:00:00',
               '2021-01-01 06:00:00', '2021-01-01 07:00:00',
               '2021-01-01 08:00:00', '2021-01-01 09:00:00',
               ...
               '2022-12-31 14:00:00', '2022-12-31 15:00:00',
               '2022-12-31 16:00:00', '2022-12-31 17:00:00',
               '2022-12-31 18:00:00', '2022-12-31 19:00:00',
               '2022-12-31 20:00:00', '2022-12-31 21:00:00',
               '2022-12-31 22:00:00', '2022-12-31 23:00:00'],
              dtype='datetime64[ns]', name='hour', length=17518, freq=None)
```

## Q3. Time trend

```
In [13]: df.index.name = None
```

```
In [14]: df['total'] = df['member'] + df['casual']
```

```
In [15]: df['total'].plot(figsize=(10,6), color='black', linewidth=1);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_1.png)

```
In [16]: df['total'].resample('D').mean().plot(figsize=(10,6), color='black', linewidth=1);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_2.png)

```
In [17]: df['total'].resample('W').mean().plot(figsize=(10,6), color='black', linewidth=1);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_3.png)

```
In [18]: df['total'].resample('M').mean().plot(figsize=(10,6), color='black', linewidth=1);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_4.png)

```
In [19]: df['casual'].resample('M').mean().plot(figsize=(10,6), color='black', linewidth=1);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_5.png)

```
In [20]: df['member'].resample('M').mean().plot(figsize=(10,6), color='black', linewidth=1);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_6.png)

## Q4. Intraday variation

```
In [21]: df['hour'] = df.index.hour
    ...: df.head()
Out[21]: 
                     casual  member  total  hour
2021-01-01 00:00:00      39      21     60     0
2021-01-01 01:00:00      48      27     75     1
2021-01-01 02:00:00      41       9     50     2
2021-01-01 03:00:00      18       7     25     3
2021-01-01 04:00:00      12       4     16     4
```

```
In [22]: df[['casual', 'hour']].groupby('hour').mean().round(1)
Out[22]: 
      casual
hour        
0       38.3
1       29.8
2       22.2
3        9.5
4        9.2
5       13.4
6       31.1
7       75.6
8      133.2
9      132.7
10     143.1
11     175.0
12     201.9
13     209.6
14     219.3
15     236.5
16     262.4
17     294.3
18     251.3
19     171.8
20     113.1
21      99.5
22      88.7
23      62.0
```

```
In [23]: df[['casual', 'hour']].groupby('hour').mean().plot.bar(figsize=(8,6), color='gray', legend=False);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_7.png)

```
In [24]: df[['member', 'hour']].groupby('hour').mean().plot.bar(figsize=(8,6), color='gray', legend=False);
```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_8.png)

```
In [25]: df[['casual', 'member', 'hour']].groupby('hour').mean().plot.bar(figsize=(8,6),
    ...: 	color=['0.4', '0.7'], stacked=True);

```

![](https://github.com/cinnData/DataSci/blob/main/Figures/fig_05e_9.png)


## Homework

1. Which are the top-10 starting stations? Are they the same as the top-10 ending stations?

2. How frequent are circular rides, starting and ending at the same station?

3. Are there stations with very low activity, so you can consider dropping them?

4. Seasonal patterns can be different across the stations of the Bay Wheels network. How can you detect the stations where the between-month variation is highest?
